//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-31294372
// Cuda compilation tools, release 11.7, V11.7.64
// Based on NVVM 7.0.1
//

.version 7.7
.target sm_86
.address_size 64

	// .globl	div_i64

.visible .entry div_i64(
	.param .u64 div_i64_param_0,
	.param .u64 div_i64_param_1,
	.param .u64 div_i64_param_2,
	.param .u64 div_i64_param_3,
	.param .u64 div_i64_param_4
)
{
	.reg .pred 	%p<27>;
	.reg .b32 	%r<63>;
	.reg .b64 	%rd<119>;


	ld.param.u64 	%rd62, [div_i64_param_0];
	ld.param.u64 	%rd63, [div_i64_param_1];
	ld.param.u64 	%rd64, [div_i64_param_2];
	ld.param.u64 	%rd60, [div_i64_param_3];
	ld.param.u64 	%rd61, [div_i64_param_4];
	cvta.to.global.u64 	%rd1, %rd64;
	cvta.to.global.u64 	%rd2, %rd63;
	cvta.to.global.u64 	%rd3, %rd62;
	mov.u32 	%r2, %ntid.y;
	mov.u32 	%r3, %ntid.x;
	mul.lo.s32 	%r4, %r3, %r2;
	mov.u32 	%r5, %ntid.z;
	mul.lo.s32 	%r6, %r4, %r5;
	mov.u32 	%r7, %nctaid.x;
	mul.lo.s32 	%r8, %r6, %r7;
	mov.u32 	%r9, %nctaid.y;
	mul.lo.s32 	%r10, %r8, %r9;
	mov.u32 	%r11, %nctaid.z;
	mul.lo.s32 	%r12, %r10, %r11;
	cvt.u64.u32 	%rd4, %r12;
	mov.u32 	%r13, %ctaid.x;
	mov.u32 	%r14, %ctaid.y;
	mad.lo.s32 	%r15, %r13, %r2, %r14;
	mov.u32 	%r16, %ctaid.z;
	mad.lo.s32 	%r17, %r15, %r5, %r16;
	mov.u32 	%r18, %tid.x;
	mad.lo.s32 	%r19, %r17, %r7, %r18;
	mov.u32 	%r20, %tid.y;
	mad.lo.s32 	%r21, %r19, %r9, %r20;
	mov.u32 	%r22, %tid.z;
	mad.lo.s32 	%r23, %r21, %r11, %r22;
	cvt.u64.u32 	%rd5, %r23;
	or.b64  	%rd65, %rd60, %rd61;
	and.b64  	%rd66, %rd65, -4294967296;
	setp.eq.s64 	%p1, %rd66, 0;
	@%p1 bra 	$L__BB0_2;

	rem.u64 	%rd105, %rd60, %rd61;
	bra.uni 	$L__BB0_3;

$L__BB0_2:
	cvt.u32.u64 	%r24, %rd61;
	cvt.u32.u64 	%r25, %rd60;
	rem.u32 	%r26, %r25, %r24;
	cvt.u64.u32 	%rd105, %r26;

$L__BB0_3:
	setp.lt.u64 	%p2, %rd5, %rd60;
	setp.eq.s64 	%p3, %rd105, 0;
	and.pred  	%p4, %p2, %p3;
	@%p4 bra 	$L__BB0_26;
	bra.uni 	$L__BB0_4;

$L__BB0_26:
	setp.gt.u64 	%p18, %rd4, %rd61;
	mov.u64 	%rd113, 1;
	@%p18 bra 	$L__BB0_30;

	and.b64  	%rd90, %rd61, -4294967296;
	setp.eq.s64 	%p19, %rd90, 0;
	@%p19 bra 	$L__BB0_29;

	div.u64 	%rd113, %rd4, %rd61;
	bra.uni 	$L__BB0_30;

$L__BB0_4:
	or.b64  	%rd67, %rd61, %rd60;
	and.b64  	%rd68, %rd67, -4294967296;
	setp.eq.s64 	%p5, %rd68, 0;
	@%p5 bra 	$L__BB0_6;

	rem.u64 	%rd106, %rd61, %rd60;
	bra.uni 	$L__BB0_7;

$L__BB0_6:
	cvt.u32.u64 	%r27, %rd60;
	cvt.u32.u64 	%r28, %rd61;
	rem.u32 	%r29, %r28, %r27;
	cvt.u64.u32 	%rd106, %r29;

$L__BB0_7:
	setp.ge.u64 	%p6, %rd5, %rd61;
	setp.ne.s64 	%p7, %rd106, 0;
	or.pred  	%p8, %p6, %p7;
	@%p8 bra 	$L__BB0_44;

	setp.gt.u64 	%p9, %rd4, %rd60;
	mov.u64 	%rd107, 1;
	@%p9 bra 	$L__BB0_12;

	and.b64  	%rd70, %rd60, -4294967296;
	setp.eq.s64 	%p10, %rd70, 0;
	@%p10 bra 	$L__BB0_11;

	div.u64 	%rd107, %rd4, %rd60;
	bra.uni 	$L__BB0_12;

$L__BB0_29:
	cvt.u32.u64 	%r46, %rd61;
	cvt.u32.u64 	%r47, %rd4;
	div.u32 	%r48, %r47, %r46;
	cvt.u64.u32 	%rd113, %r48;

$L__BB0_30:
	min.u64 	%rd38, %rd4, %rd61;
	cvt.u32.u64 	%r49, %rd38;
	cvt.u32.u64 	%r50, %rd5;
	div.u32 	%r51, %r50, %r49;
	mul.lo.s32 	%r52, %r51, %r49;
	sub.s32 	%r53, %r50, %r52;
	cvt.u64.u32 	%rd116, %r51;
	cvt.u64.u32 	%rd40, %r53;
	mul.lo.s64 	%rd41, %rd113, %rd61;
	or.b64  	%rd91, %rd60, %rd41;
	and.b64  	%rd92, %rd91, -4294967296;
	setp.eq.s64 	%p20, %rd92, 0;
	@%p20 bra 	$L__BB0_32;

	div.u64 	%rd114, %rd60, %rd41;
	bra.uni 	$L__BB0_33;

$L__BB0_32:
	cvt.u32.u64 	%r54, %rd41;
	cvt.u32.u64 	%r55, %rd60;
	div.u32 	%r56, %r55, %r54;
	cvt.u64.u32 	%rd114, %r56;

$L__BB0_33:
	mul.lo.s64 	%rd93, %rd114, %rd61;
	add.s64 	%rd94, %rd116, %rd41;
	add.s64 	%rd45, %rd94, %rd93;
	and.b64  	%rd95, %rd61, -4294967296;
	setp.eq.s64 	%p21, %rd95, 0;
	@%p21 bra 	$L__BB0_35;

	div.u64 	%rd115, %rd61, %rd38;
	bra.uni 	$L__BB0_36;

$L__BB0_35:
	cvt.u32.u64 	%r58, %rd61;
	div.u32 	%r59, %r58, %r49;
	cvt.u64.u32 	%rd115, %r59;

$L__BB0_36:
	add.s64 	%rd96, %rd40, %rd38;
	add.s64 	%rd49, %rd96, %rd115;
	setp.eq.s64 	%p22, %rd116, %rd45;
	@%p22 bra 	$L__BB0_44;

	setp.eq.s64 	%p23, %rd40, %rd49;

$L__BB0_38:
	mov.u64 	%rd117, %rd40;
	@%p23 bra 	$L__BB0_43;

$L__BB0_39:
	add.s64 	%rd52, %rd117, %rd116;
	shl.b64 	%rd97, %rd52, 3;
	add.s64 	%rd98, %rd3, %rd97;
	shl.b64 	%rd99, %rd117, 3;
	add.s64 	%rd100, %rd2, %rd99;
	ld.global.nc.u64 	%rd53, [%rd100];
	ld.global.nc.u64 	%rd54, [%rd98];
	or.b64  	%rd101, %rd54, %rd53;
	and.b64  	%rd102, %rd101, -4294967296;
	setp.eq.s64 	%p24, %rd102, 0;
	@%p24 bra 	$L__BB0_41;

	div.s64 	%rd118, %rd54, %rd53;
	bra.uni 	$L__BB0_42;

$L__BB0_41:
	cvt.u32.u64 	%r60, %rd53;
	cvt.u32.u64 	%r61, %rd54;
	div.u32 	%r62, %r61, %r60;
	cvt.u64.u32 	%rd118, %r62;

$L__BB0_42:
	add.s64 	%rd104, %rd1, %rd97;
	st.global.u64 	[%rd104], %rd118;
	add.s64 	%rd117, %rd117, %rd38;
	setp.ne.s64 	%p25, %rd117, %rd49;
	@%p25 bra 	$L__BB0_39;

$L__BB0_43:
	add.s64 	%rd116, %rd116, %rd41;
	setp.ne.s64 	%p26, %rd116, %rd45;
	@%p26 bra 	$L__BB0_38;
	bra.uni 	$L__BB0_44;

$L__BB0_11:
	cvt.u32.u64 	%r30, %rd60;
	cvt.u32.u64 	%r31, %rd4;
	div.u32 	%r32, %r31, %r30;
	cvt.u64.u32 	%rd107, %r32;

$L__BB0_12:
	min.u64 	%rd15, %rd4, %rd60;
	mul.lo.s64 	%rd16, %rd107, %rd60;
	or.b64  	%rd71, %rd61, %rd16;
	and.b64  	%rd72, %rd71, -4294967296;
	setp.eq.s64 	%p11, %rd72, 0;
	@%p11 bra 	$L__BB0_14;

	div.u64 	%rd108, %rd61, %rd16;
	bra.uni 	$L__BB0_15;

$L__BB0_14:
	cvt.u32.u64 	%r33, %rd16;
	cvt.u32.u64 	%r34, %rd61;
	div.u32 	%r35, %r34, %r33;
	cvt.u64.u32 	%rd108, %r35;

$L__BB0_15:
	cvt.u32.u64 	%r36, %rd15;
	cvt.u32.u64 	%r37, %rd5;
	mul.lo.s64 	%rd73, %rd108, %rd60;
	div.u32 	%r38, %r37, %r36;
	cvt.u64.u32 	%rd74, %r38;
	add.s64 	%rd75, %rd74, %rd16;
	add.s64 	%rd20, %rd75, %rd73;
	mul.lo.s32 	%r39, %r38, %r36;
	sub.s32 	%r1, %r37, %r39;
	and.b64  	%rd76, %rd60, -4294967296;
	setp.eq.s64 	%p12, %rd76, 0;
	@%p12 bra 	$L__BB0_17;

	div.u64 	%rd109, %rd60, %rd15;
	bra.uni 	$L__BB0_18;

$L__BB0_17:
	cvt.u32.u64 	%r41, %rd60;
	div.u32 	%r42, %r41, %r36;
	cvt.u64.u32 	%rd109, %r42;

$L__BB0_18:
	cvt.u64.u32 	%rd77, %r1;
	add.s64 	%rd78, %rd77, %rd15;
	add.s64 	%rd24, %rd78, %rd109;
	setp.eq.s64 	%p13, %rd20, 0;
	@%p13 bra 	$L__BB0_44;

	mov.u64 	%rd79, 0;
	setp.eq.s64 	%p14, %rd24, 0;
	mov.u64 	%rd110, %rd79;

$L__BB0_20:
	mov.u64 	%rd111, %rd79;
	@%p14 bra 	$L__BB0_25;

$L__BB0_21:
	add.s64 	%rd27, %rd111, %rd110;
	shl.b64 	%rd81, %rd27, 3;
	add.s64 	%rd82, %rd2, %rd81;
	ld.global.nc.u64 	%rd28, [%rd82];
	shl.b64 	%rd83, %rd111, 3;
	add.s64 	%rd84, %rd3, %rd83;
	ld.global.nc.u64 	%rd29, [%rd84];
	or.b64  	%rd85, %rd29, %rd28;
	and.b64  	%rd86, %rd85, -4294967296;
	setp.eq.s64 	%p15, %rd86, 0;
	@%p15 bra 	$L__BB0_23;

	div.s64 	%rd112, %rd29, %rd28;
	bra.uni 	$L__BB0_24;

$L__BB0_23:
	cvt.u32.u64 	%r43, %rd28;
	cvt.u32.u64 	%r44, %rd29;
	div.u32 	%r45, %r44, %r43;
	cvt.u64.u32 	%rd112, %r45;

$L__BB0_24:
	add.s64 	%rd88, %rd1, %rd81;
	st.global.u64 	[%rd88], %rd112;
	add.s64 	%rd111, %rd111, %rd15;
	setp.ne.s64 	%p16, %rd111, %rd24;
	@%p16 bra 	$L__BB0_21;

$L__BB0_25:
	add.s64 	%rd110, %rd110, %rd16;
	setp.eq.s64 	%p17, %rd110, %rd20;
	@%p17 bra 	$L__BB0_44;
	bra.uni 	$L__BB0_20;

$L__BB0_44:
	ret;

}

